#! /usr/local/bin/python

#*****************************************************************************
#
# QueuedDataManagerCloud.py
#     Utility class running as part of camera process,
#     collecting object tracks generated by Sentry/tracker,
#     and submitting them for classification by SIO.
#
#
#*****************************************************************************
#
#
# Copyright 2013-2022 Arden.ai, Inc.
#
# Licensed under the GNU GPLv3 license found at
# https://www.gnu.org/licenses/gpl-3.0.txt
#
# Alternative licensing available from Arden.ai, Inc.
# by emailing opensource@ardenai.com
#
# This file is part of the Arden AI project which can be found at
# https://github.com/ardenaiinc/ArdenAI
#
# This program is free software; you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation; using version 3 of the License.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program; if not, write to the Free Software
# Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02111, USA.
#
#
#*****************************************************************************


# Python imports...
import sys
import time
import os
import traceback
from PIL import Image
from collections import deque, defaultdict

from ObjectDetectorClient import ObjectDetectorClientLocal, ObjectDetectorClientInProcess

# Common 3rd-party imports...

# Local imports...
import MessageIds
from appCommon.CommonStrings import kThumbsSubfolder

from svsentry.Sentry import ObjectCollector, loadSentry

# Globals...
from vitaToolbox.image.ImageConversion import convertProcFrameToPIL
from vitaToolbox.ctypesUtils.LoadLibrary import LoadLibrary
from vitaToolbox.strUtils.EnsureUnicode import ensureUtf8

loadSentry(LoadLibrary, None)

_kFrameSaveInterval=1000 # distance in ms between frames we save
_kStatsReportInterval=30
_kUnknownType = "unknown"
# Maximum distance from the last Sentry appearance of the object we're willing
# to go before giving up on the track (normally, we'd wait for the cloud reports
# to catch up)
_kForceDecisionTimeout=5000

##############################################################################
class CloudStats(object):
    """ Class tracking and reporting statistics about cloud recognition
    """
    ###########################################################
    def __init__(self, reportInterval):
        super(CloudStats, self).__init__()
        self._confirmations = 0         # times cloud matched Sentry
        self._denials = 0               # times cloud contradicted Sentry
        self._improvements = 0          # times generic _kUnknownType became something else
        self._missed = 0                # times cloud didn't see anything
        self._detectionAttempts = 0
        self._objectsReported = 0
        self._reportInterval = reportInterval
        self._lastLogTime = time.time()

    ###########################################################
    def record(self, obj):
        if obj.sentryObjType == obj.detectorDecision:
            self._confirmations += 1
        elif obj.detectorDecision is _kUnknownType:
            self._missed += 1
        elif obj.sentryObjType == _kUnknownType:
            self._improvements += 1
        else:
            self._denials += 1
        self._detectionAttempts += obj.detectionEventsCount
        self._objectsReported += 1

    ###########################################################
    def _getFrameAvg(self):
        """ Get average frames that had to be ran through the cloud,
            before object type was determined.
        """
        return self._detectionAttempts / float(self._objectsReported)

    ###########################################################
    def _getSentryMatchRate(self):
        """ Get rate at which Sentry diagnosis is matched.
            Do not count cases of generic _kUnknownType diagnosis being improved
            as a failure.
        """
        return self._confirmations / float(self._objectsReported)

    ###########################################################
    def writeToLog(self, logger):
        if self._lastLogTime + self._reportInterval < time.time():
            logger.debug("Cloud stats: %d confirmations, %d denials, %d improvements, %d missed, %f Sentry match rate, ran on average of %f frames" %
                    (self._confirmations, self._denials, self._improvements, self._missed, self._getSentryMatchRate(), self._getFrameAvg()))
            self._lastLogTime = time.time()

##############################################################################
class QueuedDataManagerCloud(ObjectCollector):
    """An interface to DataManager functions to be processed remotely.

       Responsible for interpolating the results for frames not submitted to
       Sentry, as well as re-confirming classification of the objects by submitting
       frames with tracked objects to the cloud.
    """


    ###########################################################
    def __init__(self, msgQueue, pipe, id, cameraLocation, archiveDir, thumbRes, logger, inProcess=False):
        """Initialize QueuedDataManager.

        @param  msgQueue        A queue to add commands to.
        @param  pipe            A pipe for receiving feedback.
        @param  id              An id to accompany all commands.
        @param  cameraLocation  The camera location for the object.
        @param  logger          A logging utils instance.
        """
        # Call the superclass constructor.
        super(QueuedDataManagerCloud, self).__init__()

        # This is publicly accessible in case the camera location changes.
        self.cameraLocation = cameraLocation

        self._logger = logger
        self._queue = msgQueue
        self._pipe = pipe
        self._id = id

        self._objectsAdded = 0
        self._prevObjectsAdded = 0
        self._temporaryIdList = []
        self._initInterpolationState()
        # Frames currently being processed by the Sentry or by the cloud
        self._frames = {}
        self._lastFrameSavedTime = 0
        self._archiveDir = archiveDir
        self._thumbRes = thumbRes
        self._lastAnalyzedFrameMs = None
        # Last frame to flush out of here and into the backEnd
        self._lastFrameCompletedMs = 0

        # Objects reported to us by Sentry, but not yet submitted to backEnd
        self._trackedObjects = {}
        # Number of objects processed in the last frame
        self._objectsInLastFrame = 0

        self._outstandingDetectionRequests = 0
        self._lastDetectionRequestTimestamp = None
        self._lastDetectionResponseTimestamp = None
        self._lastSentryFrameTimeMs = 0

        if inProcess:
            self._httpClient = ObjectDetectorClientInProcess(self.cameraLocation, self._logger)
        else:
            self._httpClient = ObjectDetectorClientLocal(self.cameraLocation, self._logger)
        self._httpClient.start()

        self._stats = CloudStats(_kStatsReportInterval)

        self._debugMode = not hasattr(sys, 'frozen')



    ###########################################################
    def __del__(self):
        """Destructor for QueuedDataManager."""
        self.terminate()

        try:
            # Inform the back end that our pipe is no longer in use.
            self._queue.put([MessageIds.msgIdPipeFinished, self._id])
        finally:
            # Our base class, ObjectCollector, implements `__del__` also. Make
            # sure we call it without fail...
            super(QueuedDataManagerCloud, self).__del__()

    ###########################################################
    def terminate(self):
        if self._httpClient is not None:
            self._logger.debug("Destroying HTTP client")
            if self._httpClient.isAlive():
                while self._outstandingDetectionRequests > 0:
                    self._logger.debug("Destroying HTTP client - waiting for " + str(self._outstandingDetectionRequests) + " pending results")
                    self._processDetections()
                    if self._outstandingDetectionRequests > 0:
                        time.sleep(0.1)

                self._logger.debug("Destroying HTTP client - terminating")
                self._httpClient.terminate()
                self._logger.debug("Destroying HTTP client - waiting ...")
                self._httpClient.join()
                self._logger.debug("Destroying HTTP client - done")
            self._httpClient = None

    ###########################################################
    def setDebugFolder(self, folder):
        self._httpClient.setDebugFolder(folder)

    ###########################################################
    def _initInterpolationState(self):
        # Total number of frames interpolated from the start and until the currently
        # processed frame was first seen from Sentry
        self._totalInterpolated = 0
        # Current frame we receive objects for
        self._currentFrameTime = None
        self._currentFrameId = None
        # Previous frame we received objects for
        self._previousFrameTime = None
        # All the objects reported for the current frame
        self._currentFrameObjs = {}
        # All the objects reported for previous frame
        self._previousFrameObjs = {}
        # Frames lost to analytics that we need to interpolate for
        self._lostFrames = deque([])
        # Frames interpolated for current timestamp
        self._interpolatedFrames = 0
        # Timestamp of previous frame we ran interpolation for
        self._prevInterpolationTime = 0
        # Frames for submission to DB processed for the current time
        self._savedFrames = []

    ###########################################################
    def setThumbnailResolution(self, res):
        self._thumbRes = res

    ###########################################################
    def reset(self):
        """ Reset our state entirely, before new video stream starts fresh
        """
        self._initInterpolationState()

    ###########################################################
    def _checkTime(self, time, frameId):
        """ Checks the object state against new frame coming in,
            and modifies the state if new frame is detected
        """
        if self._currentFrameTime is None:
            # This is the first time we receive anything
            self._currentFrameTime = time
            self._currentFrameId = frameId
            return

        # Current implementation of Sentry serializes frames, until
        # all the objects had been labeled.
        # This may change in the future: when/if it will, most of the code here
        # and interpolation in particular will have to change
        assert time >= self._currentFrameTime

        if self._currentFrameTime == time:
            # Time hasn't changed yet
            assert frameId == self._currentFrameId
            return

        # Time had changed
        self._previousFrameTime = self._currentFrameTime
        self._previousFrameObjs = self._currentFrameObjs
        self._currentFrameTime = time
        self._currentFrameId = frameId
        self._currentFrameObjs = {}

        counter = 0
        while len(self._lostFrames) > 0 and \
            self._lostFrames[0] <= self._previousFrameTime:
            self._lostFrames.popleft()
            counter += 1
        self._totalInterpolated += counter

    ###########################################################
    def reportFrame(self, ms, frameObj=None):
        """Notify QueuedDataManager about a frame submitted to pipeline
        """
        if frameObj is None:
            # This is a dummy frame reported for interpolation purposes only
            # Pipeline hasn't seen it
            if self._currentFrameTime is None or \
               ms > self._currentFrameTime:
                self._lostFrames.append(ms)
            else:
                self._logger.error("Attempting to report frame from " + str(ms) +
                        " for interpolation. Currently processing " +
                        str(self._currentFrameTime) )
        else:
            # This is an actual frame, that is reported to the pipeline
            self._frames[ms] = frameObj

    ###########################################################
    def addObject(self, timeStart, objType=_kUnknownType):
        """Overloaded method. Insert an object into the database

        @param  timeStart       The time the object first came into view
        @param  objType         The type of this object, like 'person' or
                                'object'.
        @return objId           The id for this object assigned by the database
        """
        camObjId = self._objectsAdded
        self._objectsAdded += 1
        self._logger.debug( "addObject: " + str(timeStart) + " type=" + objType + " id=" + str(camObjId))

        queuedObjId = _QueuedObjId(self._id, camObjId, timeStart, objType)
        self._temporaryIdList.append(queuedObjId)

        # Always save a thumbnail of the first frame of each object
        if self._lastFrameSavedTime < timeStart:
            self._saveFrameThumbnail(timeStart)

        return queuedObjId.sentryId

    ###########################################################
    def _flushSavedObjects(self):
        self._interpolatedFrames = 0
        # Flush frames with previous timestamp
        for savedFrame in self._savedFrames:
            self._addFrameToDb(*savedFrame)
        self._savedFrames = []

    ###########################################################
    def getDetectionDelay(self):
        if self._lastDetectionRequestTimestamp is None or \
            self._lastDetectionResponseTimestamp is None:
            return 0
        return self._lastDetectionRequestTimestamp - self._lastDetectionResponseTimestamp

    ###########################################################
    def setAnalyticsPort(self, port):
        if self._httpClient is not None:
            self._httpClient.setAnalyticsPort(port)

    ###########################################################
    def _applyRatio(self, listOfObjects, sizeRatio):
        res = []
        for obj in listOfObjects:
            newBox = tuple([int(z * sizeRatio) for z in obj[2]])
            res.append( (obj[0], obj[1], newBox) )
        return res

    ###########################################################
    def _requestDetections(self, timestamp):
        """ Run cloud detection on the frame, if a full-size frame exists for this timestamp
        """
        frame = self._frames.get(timestamp, None)
        if frame is None:
            return

        if frame.wasResized:
            # try to obtain a full-size frame
            frameForAnalyzing = frame.getLargeFrame()
            if frameForAnalyzing is None:
                return
        else:
            # rely on locally defined interval to determine when to run detections
            kMinAnalyticsInterval = 500
            if self._lastAnalyzedFrameMs is not None and \
                frame.ms - self._lastAnalyzedFrameMs < kMinAnalyticsInterval:
                return
            frameForAnalyzing = frame

        self._lastAnalyzedFrameMs = frameForAnalyzing.ms


        sizeRatio = frame.width / float(frameForAnalyzing.width)

        # Do not run detection on objects we've made our mind about
        listWithoutDoneItems = [s for s in self._trackedObjects[timestamp] if s[0].needsDetection()]
        if len(listWithoutDoneItems) == 0:
            return

        for idObj, _, _ in listWithoutDoneItems:
            idObj.notifyDetectionRequested(timestamp)

        if self._debugMode:
            self._logger.debug("Detection request: %d - %s" % (timestamp, str(self._applyRatio(listWithoutDoneItems, sizeRatio))))
        self._httpClient.enqueWorkItem(timestamp, frameForAnalyzing, listWithoutDoneItems, sizeRatio)

        self._outstandingDetectionRequests += 1
        self._lastDetectionRequestTimestamp = timestamp

    ###########################################################
    def _frameReadyToReport(self, ms, sentryLastProcMs):
        """ Frame is ready for reporting, when all objects
            in this frame are ready
        """
        frames = self._trackedObjects.get(ms, None)
        if frames is None:
            return True

        # Iterate on objects tracked in this frame, and check if we have
        # the final verdict from the cloud, or if we've lost the object
        # before the said verdict could arrive
        for track in frames:
            obj = track[0]
            if not obj.readyToReport(sentryLastProcMs, self._logger):
                return False

        return True

    ###########################################################
    def _generateFrameReport(self, ms):
        """ Send messages to backEnd for all objects in this frame
        """
        frames = self._trackedObjects.get(ms, None)
        if frames is None:
            return

        for obj, frameId, bbox in frames:
            objType = obj.getType()

            if not obj.reported:
                camObjId = obj.dbId[1]
                self._queue.put([MessageIds.msgIdDataAddObject, self._id,
                          camObjId, ms, objType, self.cameraLocation])
                self._stats.record(obj)
                obj.reported = True

            self._queue.put([MessageIds.msgIdDataAddFrame, self._id,
                            obj.dbId,
                            frameId, ms, bbox, objType, None])

        # update the stats
        self._stats.writeToLog(self._logger)

        # Remember the last ms processed
        self._lastFrameCompletedMs = ms

    ###########################################################
    def getFinishedTimestamp(self):
        """ Return the last timestamp we're absolutetly done with
        """
        return self._lastFrameCompletedMs

    ###########################################################
    def _processCloudResults(self):
        while True:
            result = self._httpClient.getNextResult()
            if result is None:
                break

            self._outstandingDetectionRequests -= 1

            # First let objects where the positive detection occurred know
            timestamp, detections = result
            if self._debugMode:
                self._logger.debug("Detection response: %d - %s" % (timestamp, str(detections)))
            for obj, type, score, overlap in detections:
                obj.reportCloudDetection(timestamp, type, score, overlap, self._logger)

            # And then let all the rest know the detection had occurred
            frames = self._trackedObjects.get(timestamp, None)
            if frames is not None:
                for obj, _, _ in frames:
                    obj.notifyDetectionCompleted(timestamp)
            else:
                timestamps = sorted(self._trackedObjects.keys())
                tLen = len(timestamps)
                if tLen > 0:
                    self._logger.error("Couldn't find timestamp " + str(timestamp) + \
                        " have [" + str(timestamps[0]) + "," + str(timestamps[tLen-1]) + "]")
                else:
                    self._logger.error("Couldn't find timestamp " + str(timestamp) + ": no frames")

            self._lastDetectionResponseTimestamp = timestamp

            # self._logger.debug("Got result from the cloud for %d" % result[0])

    ###########################################################
    def _processDetections(self):
        self._processCloudResults()

        # See if there's anything to report to backEnd
        for k in sorted(self._trackedObjects.keys()):
            if not self._frameReadyToReport(k, self._lastSentryFrameTimeMs):
                break

            self._generateFrameReport(k)
            del self._trackedObjects[k]

        # Free all the frames that aren't needed anymore
        for timestamp in self._frames.keys():
            if timestamp <= self._lastSentryFrameTimeMs:
                del self._frames[timestamp]

        # Purge old objects
        _QueuedObjId.purgeOldIds(self._lastSentryFrameTimeMs)

    ###########################################################
    def flush(self, timeout):
        self._logger.debug("Flushing the data queue")
        start = time.time()
        while self._outstandingDetectionRequests > 0:
            # try processign new cloud detections
            self._processDetections()
            # put a limit to how long we wait for the results to flush
            if time.time() - start > timeout:
                break
            # wait a bit before polling again
            if self._outstandingDetectionRequests > 0:
                time.sleep(0.1)
        self._logger.debug("Still tracking objects in " + str(len(self._trackedObjects)) + " frames")

    ###########################################################
    def frameCompleted(self, msTimestamp, frameNum):
        """ Callback from Sentry, invoked when processing for frame with msTimestamp
            is completed, and no more events for it should be expected
        """
        # Save all the tracks from the last frame
        self._flushSavedObjects()

        # Run cloud detections, if there's anything to recognize
        if self._objectsInLastFrame > 0:
            self._requestDetections(msTimestamp)
            self._objectsInLastFrame = 0

        self._lastSentryFrameTimeMs = msTimestamp
        self._processDetections()

        # if there is no outstanding detections requests,
        # and no objects are currently being tracked, we're done up to this frame
        if self._outstandingDetectionRequests == 0 and \
            len(self._trackedObjects) == 0:
            self._lastFrameCompletedMs = msTimestamp

    ###########################################################
    def _saveFrameThumbnail(self, ms):
        if self._thumbRes == 0:
            return
        frame = self._frames.get(ms, None)
        if frame is None:
            self._logger.error("Requested timestamp " + str(ms) + " is not available for thumb")
            return
        pilFrame = convertProcFrameToPIL(frame)
        filename = os.path.basename(frame.filename)
        dirname = os.path.join(self._archiveDir, self.cameraLocation.lower(), filename[:5], kThumbsSubfolder)

        saveTo = os.path.join(dirname, str(ms)+".jpg")
        self._logger.debug("Saving jpg to " + saveTo)
        # Resize the frame, if requested thumb size is less than what we have
        if self._thumbRes < pilFrame.width:
            # This ensures the image gets scaled down to the requested size on smaller dimension
            kVeryLargeFactor = 20
            if pilFrame.width > pilFrame.height:
                size = (self._thumbRes*kVeryLargeFactor, self._thumbRes)
            else:
                size = (self._thumbRes, self._thumbRes*kVeryLargeFactor)
            pilFrame.thumbnail(size, Image.ANTIALIAS)
        try:
            if not os.path.isdir(dirname):
                os.makedirs(dirname)
            pilFrame.save(saveTo, "JPEG")
        except:
            self._logger.warning("Failed to save thumbnail to " + ensureUtf8(saveTo))

        # Even if we've failed to create a thumb, there's no reason to retry immediately
        self._lastFrameSavedTime = ms

    ###########################################################
    def _interpolateObjectAtTime(self, objId, t, frameId):
        """ Interpolate object's position at a specific time, using its positions
            in the previous and the current frames reported by Sentry
        """
        t1 = self._previousFrameTime
        b1, type1 = self._previousFrameObjs[objId]
        t2 = self._currentFrameTime
        b2, type2 = self._currentFrameObjs[objId]

        distance = t2 - t1
        d1 = t - t1
        d2 = t2 - t

        w1 = d1 / float (distance)
        w2 = d2 / float (distance)

        newBox = []
        for i in range(len(b1)):
            newBox.append( int(b1[i]*w2 + b2[i]*w1) )

        # Send a notification to the db
        self._addFrameToDb(objId, frameId, t, newBox, type1)

    ###########################################################
    def _realFrameId(self, offset):
        """ Calculate current frame ID, considering frames added by interpolation

        @param offset               How many frames had been added by interpolation
                                    while processing the current "Sentry" frame
        @return realFrameId         Converted frame ID
        """
        return self._currentFrameId + self._totalInterpolated + offset

    ###########################################################
    def _interpolateObject(self, objId):
        """ Run through the set of timestamps reported, but not submitted to Sentry,
            and interpolate the object position using its location in the last and current
            frames.
        """
        if self._previousFrameObjs is None or \
           self._currentFrameObjs is None:
            return 0
        if not objId in self._previousFrameObjs:
            return 0

        frameIdOffset = 0
        for t in self._lostFrames:
            # Only interpolate for frames in the past
            if t < self._currentFrameTime:
                self._interpolateObjectAtTime(objId, t, self._realFrameId(frameIdOffset))
                frameIdOffset += 1
            else:
                break
        return frameIdOffset

    ###########################################################
    def _addFrameToDb(self, objId, frameId, time, bbox, objType):
        # NOTE: That last message parameter that we send (`None` in this case)
        #       in the message queue is the `action` argument.
        #
        #       `action`: The action to add to the database; or None if none.
        #
        #       Previously, our pipeline runner was sending `None` anyway, but
        #       `addFrame()` used to have `action` as a parameter before we
        #       started using Sentry. So we just mention this here as a note
        #       for documentation pursposes.
        idObj = _QueuedObjId.getQueuedObjId(objId)
        idObj.reportSeen(time, self._logger)
        # save the object for this ms
        self._trackedObjects.setdefault(time,[]).append((idObj, frameId, bbox))

    ###########################################################
    def addFrame(self, objId, frameId, time, bbox, objType):
        """Overloaded method. Add a new frame of data.
           Note: multiple calls may occur for the same frameId, is this method is called
                 for each object in the frame.

        @param  objId    The id of the object in the database
        @param  frameId  The number of the frame to add
        @param  time     The time in ms that matches frame
        @param  bbox     A bounding box for the object at the given frame
        @param  objType  The object's type; passed here for speed--
                         this should match the type used for addObject().
        """
        self._checkForRealDbIds()
        # Check if this is a new frame coming from Sentry
        self._checkTime(time, frameId)

        # Sentry uses OpenCV rectangle convention, where 2nd point is exclusive
        # We expect both points being inclusive. Validate data before correction.

        updatedX = bbox[2] - 1 if bbox[2] > bbox[0] else bbox[2]
        updatedY = bbox[3] - 1 if bbox[3] > bbox[1] else bbox[3]
        updatedBBox = (bbox[0], bbox[1], updatedX, updatedY)

        # Save into list of objects for current timestamp
        self._currentFrameObjs[objId] = (updatedBBox, objType)

        # If the time changes, we reset the interpolated frames count
        if time != self._prevInterpolationTime:
            self._flushSavedObjects()
        self._prevInterpolationTime = time

        # Attempt to interpolate with the previous frame
        interpolatedFrames = self._interpolateObject(objId)

        # The number of interpolated frames may differ from object to object
        # (since an object may be new to this frame) ... we need to keep frame IDs consistent
        if interpolatedFrames > self._interpolatedFrames:
            assert self._interpolatedFrames == 0
            self._interpolatedFrames = interpolatedFrames
            newSavedFrames = []
            # Update frame IDs for previous frames processed for this timestamp
            for f in self._savedFrames:
                newSavedFrames.append ((f[0], f[1]+interpolatedFrames, f[2], f[3], f[4]))
            self._savedFrames = newSavedFrames
        elif interpolatedFrames < self._interpolatedFrames:
            assert interpolatedFrames == 0

        # Send a notification to the db
        realFrameId = self._realFrameId(self._interpolatedFrames)

        if self._debugMode:
            self._logger.debug("Motion detected at %d - frameId=%d, rect=%s" % (time, realFrameId, str(updatedBBox)))

        self._savedFrames.append((objId, realFrameId, time, updatedBBox, objType))

        # Save a jpeg, if needed
        if self._lastFrameSavedTime + _kFrameSaveInterval < time:
            self._saveFrameThumbnail(time)

        self._objectsInLastFrame += 1


    ###########################################################
    @property
    def numTotalObjectsAdded(self):
        return self._objectsAdded

    ###########################################################
    @property
    def numObjectsAddedSinceLastCheck(self):
        objectsAddedSinceLast = self._objectsAdded - self._prevObjectsAdded
        self._prevObjectsAdded = self._objectsAdded
        return objectsAddedSinceLast


    ###########################################################
    def _checkForRealDbIds(self):
        """This polls our pipe looking for real database IDs."""

        # Data on the pipe should come back in the order we added objects.
        # If we get something unexpected, we'll just drop stuff from our
        # self._temporaryIdList until we match up, since it implies that the
        # back end somehow got mixed up.
        while self._pipe.poll(0):
            (tempId, realId) = self._pipe.recv()

            while self._temporaryIdList:
                queuedObjId = self._temporaryIdList.pop(0)
                if queuedObjId.dbId == (self._id, tempId):
                    break
                else:
                    self._logger.warn("Never got mapping for ID %s" %
                                      str(queuedObjId.dbId))
            else: # didn't break; ran out of temporary IDs
                # Really don't expect this (how would an extra thing get in
                # the list?)  If we expected it, we should do something like
                # keep track of mappings that we tossed above, then restore
                # them all here.
                self._logger.error("Received unexpected mapping: %d -> %d" % (
                                   tempId, realId))
                return

            self._logger.debug("Received mapping: %d -> %d" % (
                               tempId, realId))

            queuedObjId.dbId = realId


##############################################################################
class _QueuedObjId(object):
    """Internal class that we return as the database ID.

    The reason that we have this class is that it easily allows us to switch
    from using our temporary ID to our real ID once the real ID arrives on
    the pipe.

    When we're running with a temprary ID, self.dbId will be a tuple:
      (camId, camObjId)
    ...once we get a real ID, it will just be the dbId returned by the data mgr.
    """

    _idToQueuedObj = {}
    _idNum = -1
    _idLastPurgeTime = time.time()
    _idPurgeInterval = 30       # purge old IDs every 30s
    _idPurgeTimeout = 5*60      # ID is old after it hasn't been seen for 5 minutes
    _minDetectionEvents = 3
    _maxDetectionEvents = 8

    ###########################################################
    def __str__(self):
        return str(self._idNum) if self._idNum >= 0 else str(self._idToQueuedObj)
    __repr__ = __str__

    ###########################################################
    @classmethod
    def purgeOldIds(cls, ms):
        """ Remove objects not tracked any longer
        @param  ms      ms of the current frame being processed
        """
        if cls._idLastPurgeTime + cls._idPurgeInterval > ms:
            return
        # delete info about objects we haven't seen in awhile
        for idNum in cls._idToQueuedObj.keys():
            if cls._idToQueuedObj[idNum].lastSeenBySentry + cls._idPurgeTimeout < ms:
                del cls._idToQueuedObj[idNum]
        cls._idLastPurgeTime = ms


    ###########################################################
    @classmethod
    def getQueuedObjId(cls, theId):
        qObjId = cls._idToQueuedObj.get(theId, None)
        if qObjId is not None:
            return qObjId
        raise RuntimeError("Id '%s' does not exist." % theId)


    ###########################################################
    def __init__(self, camId, camObjId, ms, objType):
        """_QueuedObjId constructor.

        @param  camId     The ID number of the queue.
        @param  camObjId  The number of objects that have been created
                          by the queue so far.
        """
        super(_QueuedObjId, self).__init__()

        _QueuedObjId._idNum += 1
        idNum = _QueuedObjId._idNum

        self.dbId = (camId, camObjId)
        self.sentryId = idNum
        self.firstSeenBySentry = ms   # first time this object had been seen by Sentry
        self.lastSeenBySentry = ms    # last time this object had been seen by Sentry
        self.sentryObjType = objType  # object type as Sentry sees it
        self.externalDetections = defaultdict(list) # detection results for all the past frames
        self.lastDetectionRequestTime = None        # last detection requested for a frame containing this object
        self.lastDetectionResponseTime = 0       # last time we've been notified of a detection response (not the same as result)
        self.lastDetectionEventTime = None          # timestamp of last supplied detection result
        self.detectionEventsCount = 0 # how many frames containing this object were analyzed by the detector
        self.detectorDecision = None  # The type we decide on, based on all factors
        self.detectionsRequested = 0   # number of detection requests sent for this object
        self.reported = False          # whether the object was reported
        self.sentryFramesSeen = 0     # number of times this object was seen by sentry

        _QueuedObjId._idToQueuedObj[idNum] = self

    ###########################################################
    def needsDetection(self):
        return not self.reported and \
                self.detectionsRequested < _QueuedObjId._maxDetectionEvents

    ###########################################################
    def reportSeen(self, ms, logger):
        # logger.debug("SentryID=" + str(self.sentryId) + ": seen at " + str(ms) )
        self.lastSeenBySentry = ms
        self.sentryFramesSeen += 1

    ###########################################################
    def getType(self):
        return self.detectorDecision

    ###########################################################
    def reportCloudDetection(self, ms, type, score, overlap, logger):
        """ Notify the object whenever detection result is received for a particular frame
        """
        if self.detectorDecision is not None:
            # do not update the object if final determination had been made
            return

        self.lastDetectionEventTime = ms
        self.externalDetections[ms].append((type, score, overlap))

    ###########################################################
    def notifyDetectionRequested(self, ms):
        """ Notify we've requested detection for a frame with this object
        """
        self.detectionsRequested += 1
        self.lastDetectionRequestTime = ms

    ###########################################################
    def notifyDetectionCompleted(self, ms):
        """ Notify the object whenever detection attempt occurs for a particular frame
        """
        self.lastDetectionResponseTime = ms
        if self.detectorDecision is not None:
            # do not update the object if final determination had been made
            return

        self.detectionEventsCount += 1
        if self.lastDetectionEventTime == ms:
            # we've seen a result associated with this ms
            return

        # Make 'unknown' high enough to count, but not so high that it trumps
        # good matches we may see in other frames
        self.externalDetections[ms].append(("unknown", 0.5, 0.5))


    ###########################################################
    def _getScoresForObservedTypes(self):
        """ Returns sum of all scores and overlaps observed for each type across all frame.
            If a type is seen multiple times in a single frame, best object is used to
            represent that frame.
        """
        sumOverlap = defaultdict(float)
        sumScore  = defaultdict(float)
        sumFrames = defaultdict(int)

        # Iterate on all the frames, and pick the best object of each type in each frame
        # Use that objects overlap and score for a decision
        for ms in sorted(self.externalDetections.keys()):
            bestObjectsInFrame = {}
            for type, score, overlap in self.externalDetections[ms]:
                if not type in bestObjectsInFrame:
                    prevObject = (0, 0, 0)
                else:
                    prevObject = bestObjectsInFrame[type]
                if prevObject[0] + prevObject[1] < score + overlap:
                    sumOverlap[type] += ( overlap - prevObject[0] )
                    sumScore[type] += ( score - prevObject[1] )
                    sumFrames[type] += ( 1 - prevObject[2] )
                    bestObjectsInFrame[type] = (overlap, score, 1)

        return sumFrames, sumScore, sumOverlap

    ###########################################################
    def _summarizeScores(self, forceDecision, logger):
        kHighConfidenceScore = 0.9
        kHighConfidenceOverlap = 0.8

        sumFrames, sumScore, sumOverlap = self._getScoresForObservedTypes()
        frameCount = len(self.externalDetections.keys())

        highConfidenceTypes = []
        bestSuperscore = 0
        bestSuperscoreType = None
        allTypes = sumFrames.keys()

        # See which object types we've seen so far, and if any of those stand out
        for type in allTypes:
            superscore = sumScore[type]+sumOverlap[type]
            if superscore > bestSuperscore:
                bestSuperscore = superscore
                bestSuperscoreType = type
            # Object is considered to be a high-confidence if
            # - it appears in all analyzed frames
            # - its average score and overlap fall within thresholds
            if sumFrames[type] == frameCount and \
                sumScore[type] / float(frameCount) > kHighConfidenceScore and \
                sumOverlap[type] / float(frameCount) > kHighConfidenceOverlap:
                highConfidenceTypes.append(type)

        # Determine if the decision can be made now
        if len(highConfidenceTypes) == 1:
            typeFrames = sumFrames[type]
            avgScore = sumScore[type] / float(typeFrames)
            avgOverlap = sumOverlap[type] / float(typeFrames)
            logger.debug("SentryID=%d detection completed :" \
                        " classifying as %s sentry=%s avgScore=%.2f" \
                        " avgOverlap=%.2f typeFrames=%d/%d typesSeens=%s" % \
                        (self.sentryId, \
                        highConfidenceTypes[0], self.sentryObjType, avgScore, \
                         avgOverlap, typeFrames, frameCount, str(allTypes) ) )
            self.detectorDecision = highConfidenceTypes[0]
        elif len(highConfidenceTypes) != 0 and not forceDecision:
            logger.debug("SentryID=" + str(self.sentryId) + ": " + \
                        " postponing classification; could be one of " + str(highConfidenceTypes) )

        # Force decision if we have to
        if self.detectorDecision is None and forceDecision:
            type = bestSuperscoreType
            typeFrames = sumFrames[type]
            if type == None or typeFrames == 0 or frameCount == 0:
                # This would happen, when Sentry-detected object is so
                # short-lived, that we don't see any full-size frames to
                # run detection on
                logger.error("SentryID=" + str(self.sentryId) + ":" + \
                            "    no frames!." + \
                            " sentry=" + str(self.sentryObjType) + \
                            " frameCount=" + str(frameCount) + \
                            " typesSeen=" + str(allTypes))
                self.detectorDecision = self.sentryObjType
            else:
                # In this case, we've either lost the track or decided we've
                # seen enough (> max frames)
                avgScore = sumScore[type] / float(typeFrames)
                avgOverlap = sumOverlap[type] / float(typeFrames)
                logger.debug("SentryID=%d detection completed :" \
                            " forcing decision to %s sentry=%s avgScore=%.2f" \
                            " avgOverlap=%.2f typeFrames=%d/%d typesSeens=%s" % \
                            (self.sentryId, \
                            type, self.sentryObjType, avgScore, \
                            avgOverlap, typeFrames, frameCount, str(allTypes) ) )
                self.detectorDecision = type


    ###########################################################
    def readyToReport(self, lastFrameProcessedBySentry, logger):
        # Check if this object has been reported at least once
        if self.detectorDecision is not None:
            return True

        # only run summary if have enough detections to go by
        needToCheck = self.detectionEventsCount >= _QueuedObjId._minDetectionEvents

        # max detections ran
        enoughDetecting = self.detectionEventsCount >= _QueuedObjId._maxDetectionEvents

        # The track is lost when:
        # - last frame coming from the tracker did not include this object
        # - AND we've never got a chance to ask for a detection
        #   (usually because object livespan is too short to include a non-resized frame)
        # - OR we've received responses to all the detection requests we sent
        trackLost = self.lastSeenBySentry < lastFrameProcessedBySentry and \
                    ( self.lastDetectionRequestTime is None or \
                    self.lastDetectionResponseTime >= self.lastDetectionRequestTime )
        if trackLost:
            logger.debug("SentryID=" + str(self.sentryId) + ": Track lost - " + \
                        " first=" + str(self.firstSeenBySentry) + \
                        " last=" + str(self.lastSeenBySentry) + \
                        " sentry=" + str(lastFrameProcessedBySentry) + \
                        " events=" + str(self.detectionEventsCount) + \
                        " sentryFrames=" + str(self.sentryFramesSeen) )

        if needToCheck or trackLost:
            try:
                self._summarizeScores(trackLost or enoughDetecting, logger)
            except:
                logger.error("Exception processing scores ... trackLost=%s" \
                            " detectionEventsCount=%d"
                            " detections=%s"
                            " error=%s" %
                            (str(trackLost), self.detectionEventsCount, str(self.externalDetections), traceback.format_exc()))

        return self.detectorDecision is not None
